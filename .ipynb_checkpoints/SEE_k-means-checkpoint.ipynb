{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "It finds the directory where the script is located, creates a file named **med_events.csv**, and reads the data equivalent to the reading of the R script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m script_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18;43m__file__\u001b[39;49m)) \n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(script_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmed_events.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m      3\u001b[0m med_events \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "script_dir = os.path.dirname(os.path.abspath(__file__)) \n",
    "file_path = os.path.join(script_dir, \"med_events.csv\")  \n",
    "med_events = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data:\n",
    "**pnr**: Patient Number <br>\n",
    "**eksd**: A date string (prescription date) <br>\n",
    "**perday**: Some daily measure <br>\n",
    "**ATC**: A drug code <br>\n",
    "**dur_original**: The original duration <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExamplePats = med_events.copy()\n",
    "tidy = ExamplePats.copy()\n",
    "tidy.columns = [\"pnr\", \"eksd\", \"perday\", \"ATC\", \"dur_original\"]\n",
    "tidy['eksd'] = pd.to_datetime(tidy['eksd'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting a Parameter\n",
    "**arg1** is used to filter the data. In this case, only rows where ATC column equals to **medA** will be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg1 = \"medA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Function\n",
    "This function processes the data using The Sessa Empirical Estimator which uses K-means clustering. There are a few disadvantages to this which is why there will be a comparisson with another clustering method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def See(arg1):\n",
    "  C09CA01 = tidy[tidy['ATC'] == arg1].copy()\n",
    "  Drug_see_p0 = C09CA01.copy()\n",
    "  Drug_see_p1 = C09CA01.copy()\n",
    "  Drug_see_p1 = Drug_see_p1.sort_values(by=['pnr', 'eksd'])\n",
    "  Drug_see_p1['prev_eksd'] = Drug_see_p1.groupby('pnr')['eksd'].shift(1)\n",
    "  Drug_see_p1 = Drug_see_p1.dropna(subset=['prev_eksd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function accepts one parameter (drug code which in this case is medA). <br>\n",
    "It filters the tidy DataFrame where ATC equals to the argument passed which is copied into **C09CA01** <br>\n",
    "<br>\n",
    "We create 2 copies **Drug_see_p0** for merging results and **Drug_see_p1** for processing. Then, we sort and compute the previous dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Drug_see_p1 = Drug_see_p1.groupby('pnr', group_keys=False).apply(lambda x: x.sample(n=1, random_state=1234))\n",
    "    Drug_see_p1 = Drug_see_p1[['pnr', 'eksd', 'prev_eksd']].copy()\n",
    "    Drug_see_p1['event.interval'] = (Drug_see_p1['eksd'] - Drug_see_p1['prev_eksd']).dt.days.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then do random sampling of patients (grouped by pnr). This also retains only **pnr**, **eksd** and **prev_eksd** columns. <br>\n",
    "It also computes for the time difference in days between the **eksd** and **prev_eksd**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ecdf_func = ECDF(Drug_see_p1['event.interval'])\n",
    "    x_vals = ecdf_func.x\n",
    "    y_vals = ecdf_func.y\n",
    "    dfper = pd.DataFrame({'x': x_vals, 'y': y_vals})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the ECDF, which is from the statsmodels, to calculate the empirical cumulative distribution of **event_interval**. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dfper = dfper[dfper['y'] <= 0.8]\n",
    "    dfper = dfper[np.isfinite(dfper['x'])]\n",
    "    max_x = dfper['x'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This filters the rows where the cumulative probability is less than or equal to 80%. We also remove infinities to ensure that only finite **x** values remain which prevents errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axs[0].plot(dfper['x'], dfper['y'])\n",
    "    axs[0].set_title(\"80% ECDF\")\n",
    "    axs[1].plot(x_vals, y_vals)\n",
    "    axs[1].set_title(\"100% ECDF\")\n",
    "    plt.show()\n",
    "\n",
    "    m1 = Drug_see_p1['pnr'].value_counts()\n",
    "    m1.plot(kind='bar', title=\"Frequency of pnr\")\n",
    "    plt.show()\n",
    "\n",
    "    ni = max_x\n",
    "    Drug_see_p2 = Drug_see_p1[Drug_see_p1['event.interval'] <= ni].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a figure with 2 side-by-side plots. <br>\n",
    "**Left Plot**: plots the filtered ECDF (80% of the data) <br>\n",
    "**Right Plot**: Plots the complete ECDF (100%) <br>\n",
    "**Frequency Count**: Counts how many times each patient appears. <br>\n",
    "**Bar Plot**: Plots the frequency counts as a bar chart. <br><br>\n",
    "Then we filter based on maximum ECDF Value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    log_event = np.log(Drug_see_p2['event.interval'].astype(float))\n",
    "    density = gaussian_kde(log_event)\n",
    "    x1 = np.linspace(log_event.min(), log_event.max(), 100)\n",
    "    y1 = density(x1)\n",
    "    plt.plot(x1, y1)\n",
    "    plt.title(\"Log(event interval)\")\n",
    "    plt.show()\n",
    "    z1 = x1.max()\n",
    "\n",
    "    a_df = pd.DataFrame({'x': x1, 'y': y1})\n",
    "    scaler = StandardScaler()\n",
    "    a_scaled = scaler.fit_transform(a_df)\n",
    "    a_scaled = pd.DataFrame(a_scaled, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes the natural logarithm of the **event_interval** and uses the **gaussian_kde** to estimate the density of the log-transformed data which can be used to create 100 evenly spaced values between the minimum and maximum of the log-transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    best_k = None\n",
    "    best_score = -1\n",
    "    scores = {}\n",
    "    for k in range(2, 10):\n",
    "        km = KMeans(n_clusters=k, random_state=1234, n_init=10)\n",
    "        km.fit(a_scaled)\n",
    "        score = silhouette_score(a_scaled, km.labels_)\n",
    "        scores[k] = score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    plt.plot(list(scores.keys()), list(scores.values()), marker='o')\n",
    "    plt.title(\"Silhouette Analysis\")\n",
    "    plt.xlabel(\"Number of clusters\")\n",
    "    plt.ylabel(\"Silhouette score\")\n",
    "    plt.show()\n",
    "    max_cluster = best_k\n",
    "\n",
    "    km_final = KMeans(n_clusters=max_cluster, random_state=1234, n_init=10)\n",
    "    km_final.fit(dfper[['x']])\n",
    "    dfper['cluster'] = km_final.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now iterate though possible numbers of clusters (loop over k) and sets the optimal number of clusters based on the highest silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ni2 = dfper.groupby('cluster')['x'].apply(lambda s: np.log(s).min())\n",
    "    ni3 = dfper.groupby('cluster')['x'].apply(lambda s: np.log(s).max())\n",
    "    ni2_df = ni2.reset_index().rename(columns={'x': 'Results'})\n",
    "    ni3_df = ni3.reset_index().rename(columns={'x': 'Results'})\n",
    "    ni2_df['Results'] = ni2_df['Results'].replace(-np.inf, 0)\n",
    "    nif = pd.concat([ni2_df, ni3_df.iloc[:, 1]], axis=1)\n",
    "    nif.columns = ['Cluster', 'Results', 'Results_1']\n",
    "    nif = nif[['Cluster', 'Results']]\n",
    "    nif['Results'] = np.exp(nif['Results'])\n",
    "    nif['Results_1'] = np.exp(ni3_df['Results'])\n",
    "    ni4 = dfper.groupby('cluster')['x'].apply(lambda s: np.median(np.log(s)))\n",
    "    ni4_df = ni4.reset_index().rename(columns={'x': 'Results'})\n",
    "    ni4_df = ni4_df.rename(columns={'cluster': 'Cluster'})\n",
    "    nif = pd.merge(nif, ni4_df, on='Cluster')\n",
    "    nif.columns = ['Cluster', 'Minimum', 'Maximum', 'Median']\n",
    "    nif['Median'] = nif['Median'].replace(-np.inf, 0)\n",
    "    nif = nif[nif['Median'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now summarizing clusters. For each cluster, **ni2** computes for the minimum of the log-transformed x values while **ni3** is for the maximum. We are also combining the 2 DataFrames sibe by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Drug_see_p1['key'] = 1\n",
    "    nif['key'] = 1\n",
    "    results = pd.merge(Drug_see_p1, nif, on='key')\n",
    "    results.drop('key', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Join by creating a temporary column key with a constant value in both DataFrames, then we remove it after merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if 'Cluster_y' not in results.columns:\n",
    "        results = results.rename(columns={'Cluster_x': 'Cluster', 'Cluster_y': 'Cluster'})\n",
    "    results['Final_cluster'] = np.where(\n",
    "        (results['event.interval'] >= results['Minimum']) & (results['event.interval'] <= results['Maximum']),\n",
    "        results['Cluster'], np.nan\n",
    "    )\n",
    "    results = results[~results['Final_cluster'].isna()].copy()\n",
    "    results['Median'] = np.exp(results['Median'])\n",
    "    results = results[['pnr', 'Median', 'Cluster']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some checks here to check if the merged DataFrame has a column named **Cluster_y**. if not, it renames it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    t1 = results['Cluster'].value_counts().reset_index()\n",
    "    t1.columns = ['Cluster', 'Freq']\n",
    "    t1 = t1.sort_values(by='Freq', ascending=False)\n",
    "    most_freq = t1.iloc[0]['Cluster']\n",
    "    t1 = pd.DataFrame({'Cluster': [most_freq]})\n",
    "    t1['Cluster'] = t1['Cluster'].astype(float)\n",
    "    results['Cluster'] = results['Cluster'].astype(float)\n",
    "    t1_merged = pd.merge(t1, results, on='Cluster', how='inner')\n",
    "    t1_merged = t1_merged.iloc[[0], :]\n",
    "    if 'Freq' in t1_merged.columns:\n",
    "        t1_merged = t1_merged.drop(columns=['Freq'])\n",
    "    t1 = t1_merged.copy()\n",
    "    Drug_see_p1 = pd.merge(Drug_see_p1, results, on='pnr', how='left')\n",
    "    Drug_see_p1['Median'] = Drug_see_p1['Median'].fillna(t1.iloc[0]['Median'])\n",
    "    Drug_see_p1['Cluster'] = Drug_see_p1['Cluster'].fillna(0)\n",
    "    Drug_see_p1['event.interval'] = Drug_see_p1['event.interval'].astype(float)\n",
    "    Drug_see_p1['test'] = np.round(Drug_see_p1['event.interval'] - Drug_see_p1['Median'], 1)\n",
    "    \n",
    "    Drug_see_p3 = Drug_see_p1[['pnr', 'Median', 'Cluster']].copy()\n",
    "    \n",
    "    Drug_see_p0 = pd.merge(Drug_see_p0, Drug_see_p3, on='pnr', how='left')\n",
    "    Drug_see_p0['Median'] = pd.to_numeric(Drug_see_p0['Median'], errors='coerce')\n",
    "    Drug_see_p0['Median'] = Drug_see_p0['Median'].fillna(t1.iloc[0]['Median'])\n",
    "    Drug_see_p0['Cluster'] = Drug_see_p0['Cluster'].fillna(0)\n",
    "    \n",
    "    return Drug_see_p0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a frequency table for **Cluster** in the results DataFrame. This determines the cluster that appears most frequently. It merges this information back to **results** and then into **Drug_see_p1**, then fills missing values in the **Median** and **Cluster**.<br><br>\n",
    "It then computes a new column **test** as the difference between **event.interval** and **Median**, then merges **Drug_see_p0** and **Drug_see_p1** so that final durations and clusters are assigned. This makes it so that **Drug_see_p0** will contain and be returned with the processed data with assigned durations and clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Duration\n",
    "This creates boxplots for us to visualize the duration by event number (difference between prescription)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_assumption(arg1):\n",
    "    arg1 = arg1.sort_values(by=['pnr', 'eksd'])\n",
    "    arg1['prev_eksd'] = arg1.groupby('pnr')['eksd'].shift(1)\n",
    "    Drug_see2 = arg1.copy()\n",
    "    Drug_see2['p_number'] = Drug_see2.groupby('pnr').cumcount() + 1\n",
    "    Drug_see2 = Drug_see2[Drug_see2['p_number'] >= 2].copy()\n",
    "    Drug_see2 = Drug_see2[['pnr', 'eksd', 'prev_eksd', 'p_number']].copy()\n",
    "    Drug_see2['Duration'] = (Drug_see2['eksd'] - Drug_see2['prev_eksd']).dt.days.astype(float)\n",
    "    Drug_see2['p_number'] = Drug_see2['p_number'].astype(str)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x='p_number', y='Duration', data=Drug_see2)\n",
    "    plt.title(\"Boxplot of Duration by p_number\")\n",
    "    plt.show()\n",
    "    \n",
    "    medians_of_medians = Drug_see2.groupby('pnr')['Duration'].median().reset_index().rename(columns={'Duration': 'median_duration'})\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x='p_number', y='Duration', data=Drug_see2)\n",
    "    global_median = medians_of_medians['median_duration'].mean()\n",
    "    plt.axhline(global_median, linestyle='dashed', color='red')\n",
    "    plt.title(\"Boxplot of Duration with Median Line\")\n",
    "    plt.show()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It sorts the data by **pnr** and **eksd** and computes the previous date for each patient. It then assigns event numbers and filters over it which keeps one event where **p_number** is 2 or higher since the first event has no previous event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data and Running the Functions\n",
    "Lastly, we run the functions to see the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medA = See(\"medA\")\n",
    "medB = See(\"medB\")\n",
    "see_assumption(medA)\n",
    "see_assumption(medB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
